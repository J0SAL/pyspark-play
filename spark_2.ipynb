{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1PAN_X9raGwEsJkznTNSyY4IAIWmG4SGb",
      "authorship_tag": "ABX9TyOz/+uDwOOYJbdGVhLxx652",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/J0SAL/pyspark-play/blob/main/spark_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Topics Covered\n",
        "* Dropping Columns\n",
        "* Dropping Rows\n",
        "* Various Parameter In Dropping functionalities\n",
        "* Handling Missing values by Mean, MEdian And Mode"
      ],
      "metadata": {
        "id": "bjgEVrkXX7Oe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "laLsTHHzTf2o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1175fb32-09d6-45c1-cc40-29c6562959ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.1.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.1-py2.py3-none-any.whl size=311285387 sha256=0ed394b02eebafdf6a5a31d6272758b8368bdfd38f64481da66578ecac51e821\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/77/a3/ff2f74cc9ab41f8f594dabf0579c2a7c6de920d584206e0834\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating Spark Session\n",
        "from pyspark.sql import SparkSession\n",
        "spark=SparkSession.builder.appName('Dataframe').getOrCreate()"
      ],
      "metadata": {
        "id": "xShPHXj8WhPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "ZQCu6PNQZaW5",
        "outputId": "78566287-ed36-403e-d349-7cf0af270e82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f9e8389d810>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://d240b6fa7938:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.4.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Dataframe</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read dataset - way1\n",
        "filepath = '/content/drive/MyDrive/Colab Notebooks/spark/test2.csv'\n",
        "df_pyspark=spark.read.option('header','true').csv(filepath,inferSchema=True)"
      ],
      "metadata": {
        "id": "6-qFoVgmZe6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrsqLbtJal4v",
        "outputId": "96e8a77d-deb7-4bce-f144-0ed6f2e8629c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----+----------+------+\n",
            "|     Name| age|Experience|Salary|\n",
            "+---------+----+----------+------+\n",
            "|    Krish|  31|        10| 30000|\n",
            "|Sudhanshu|  30|         8| 25000|\n",
            "|    Sunny|  29|         4| 20000|\n",
            "|     Paul|  24|         3| 20000|\n",
            "|   Harsha|  21|         1| 15000|\n",
            "|  Shubham|  23|         2| 18000|\n",
            "|   Mahesh|null|      null| 40000|\n",
            "|     null|  34|        10| 38000|\n",
            "|     null|  36|      null|  null|\n",
            "+---------+----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dropping Columns"
      ],
      "metadata": {
        "id": "Bd_OzjBfthGm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.drop('Name').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwGvl74GbEf-",
        "outputId": "a54393c5-7fee-4430-de7b-06d90fb5b3f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----------+------+\n",
            "| age|Experience|Salary|\n",
            "+----+----------+------+\n",
            "|  31|        10| 30000|\n",
            "|  30|         8| 25000|\n",
            "|  29|         4| 20000|\n",
            "|  24|         3| 20000|\n",
            "|  21|         1| 15000|\n",
            "|  23|         2| 18000|\n",
            "|null|      null| 40000|\n",
            "|  34|        10| 38000|\n",
            "|  36|      null|  null|\n",
            "+----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dropping Rows with Null"
      ],
      "metadata": {
        "id": "lY1z-t7WtzFq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.na.drop().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jT1-4DS2bWgV",
        "outputId": "7f0c3b63-7994-4259-f067-41049093b516"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+\n",
            "|     Name|age|Experience|Salary|\n",
            "+---------+---+----------+------+\n",
            "|    Krish| 31|        10| 30000|\n",
            "|Sudhanshu| 30|         8| 25000|\n",
            "|    Sunny| 29|         4| 20000|\n",
            "|     Paul| 24|         3| 20000|\n",
            "|   Harsha| 21|         1| 15000|\n",
            "|  Shubham| 23|         2| 18000|\n",
            "+---------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dropping Rows with Null ~ parameters"
      ],
      "metadata": {
        "id": "NTDwMfCyt3s7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### how = any : any null then delete\n",
        "df_pyspark.na.drop(how=\"any\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dZH5ZGDbZRQ",
        "outputId": "8856e28a-4367-4f78-bbd2-7fab52e7decc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+\n",
            "|     Name|age|Experience|Salary|\n",
            "+---------+---+----------+------+\n",
            "|    Krish| 31|        10| 30000|\n",
            "|Sudhanshu| 30|         8| 25000|\n",
            "|    Sunny| 29|         4| 20000|\n",
            "|     Paul| 24|         3| 20000|\n",
            "|   Harsha| 21|         1| 15000|\n",
            "|  Shubham| 23|         2| 18000|\n",
            "+---------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### how = all : all null then delete\n",
        "df_pyspark.na.drop(how=\"all\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DF3EdQjkbb1H",
        "outputId": "e689ed3d-d180-4846-b5f7-25d73bff9841"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----+----------+------+\n",
            "|     Name| age|Experience|Salary|\n",
            "+---------+----+----------+------+\n",
            "|    Krish|  31|        10| 30000|\n",
            "|Sudhanshu|  30|         8| 25000|\n",
            "|    Sunny|  29|         4| 20000|\n",
            "|     Paul|  24|         3| 20000|\n",
            "|   Harsha|  21|         1| 15000|\n",
            "|  Shubham|  23|         2| 18000|\n",
            "|   Mahesh|null|      null| 40000|\n",
            "|     null|  34|        10| 38000|\n",
            "|     null|  36|      null|  null|\n",
            "+---------+----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### threshold = VALUE\n",
        "# drop rows that have less than thresh non-null values.\n",
        "df_pyspark.na.drop(thresh=2).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33j4yzUdbdgH",
        "outputId": "dacebffe-9ad5-48e3-9b2e-245c2e46bdd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----+----------+------+\n",
            "|     Name| age|Experience|Salary|\n",
            "+---------+----+----------+------+\n",
            "|    Krish|  31|        10| 30000|\n",
            "|Sudhanshu|  30|         8| 25000|\n",
            "|    Sunny|  29|         4| 20000|\n",
            "|     Paul|  24|         3| 20000|\n",
            "|   Harsha|  21|         1| 15000|\n",
            "|  Shubham|  23|         2| 18000|\n",
            "|   Mahesh|null|      null| 40000|\n",
            "|     null|  34|        10| 38000|\n",
            "+---------+----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Subset\n",
        "# only delete the row if there is null in Age i.e. specified column\n",
        "df_pyspark.na.drop(how=\"any\",subset=['Age']).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXz0OPAavfdY",
        "outputId": "5f92f846-849c-4de6-ec12-5e2cf3f218f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+\n",
            "|     Name|age|Experience|Salary|\n",
            "+---------+---+----------+------+\n",
            "|    Krish| 31|        10| 30000|\n",
            "|Sudhanshu| 30|         8| 25000|\n",
            "|    Sunny| 29|         4| 20000|\n",
            "|     Paul| 24|         3| 20000|\n",
            "|   Harsha| 21|         1| 15000|\n",
            "|  Shubham| 23|         2| 18000|\n",
            "|     null| 34|        10| 38000|\n",
            "|     null| 36|      null|  null|\n",
            "+---------+---+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Handling Missing values by Mean, MEdian And Mode"
      ],
      "metadata": {
        "id": "QoH2fT_ku1Lt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Filling the Missing Value\n",
        "df_pyspark.na.fill(10).show()\n",
        "df_pyspark.na.fill(\"ten\").show()\n",
        "# here it checks the data type"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkTTM4wLbjp2",
        "outputId": "fb7dcdb0-0b9b-47d4-e856-fe3f81b72c63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+\n",
            "|     Name|age|Experience|Salary|\n",
            "+---------+---+----------+------+\n",
            "|    Krish| 31|        10| 30000|\n",
            "|Sudhanshu| 30|         8| 25000|\n",
            "|    Sunny| 29|         4| 20000|\n",
            "|     Paul| 24|         3| 20000|\n",
            "|   Harsha| 21|         1| 15000|\n",
            "|  Shubham| 23|         2| 18000|\n",
            "|   Mahesh| 10|        10| 40000|\n",
            "|     null| 34|        10| 38000|\n",
            "|     null| 36|        10|    10|\n",
            "+---------+---+----------+------+\n",
            "\n",
            "+---------+----+----------+------+\n",
            "|     Name| age|Experience|Salary|\n",
            "+---------+----+----------+------+\n",
            "|    Krish|  31|        10| 30000|\n",
            "|Sudhanshu|  30|         8| 25000|\n",
            "|    Sunny|  29|         4| 20000|\n",
            "|     Paul|  24|         3| 20000|\n",
            "|   Harsha|  21|         1| 15000|\n",
            "|  Shubham|  23|         2| 18000|\n",
            "|   Mahesh|null|      null| 40000|\n",
            "|      ten|  34|        10| 38000|\n",
            "|      ten|  36|      null|  null|\n",
            "+---------+----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# can mention specific columns as well\n",
        "\n",
        "df_pyspark.na.fill(420, ['Experience', 'Salary']).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5XdSGZdbvVj",
        "outputId": "f5d660c8-17fb-4e2f-ac28-1e91569ab64c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----+----------+------+\n",
            "|     Name| age|Experience|Salary|\n",
            "+---------+----+----------+------+\n",
            "|    Krish|  31|        10| 30000|\n",
            "|Sudhanshu|  30|         8| 25000|\n",
            "|    Sunny|  29|         4| 20000|\n",
            "|     Paul|  24|         3| 20000|\n",
            "|   Harsha|  21|         1| 15000|\n",
            "|  Shubham|  23|         2| 18000|\n",
            "|   Mahesh|null|       420| 40000|\n",
            "|     null|  34|        10| 38000|\n",
            "|     null|  36|       420|   420|\n",
            "+---------+----+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import Imputer\n",
        "# it supports numerical data only\n",
        "\n",
        "imputer = Imputer(\n",
        "    inputCols=['age', 'Experience', 'Salary'],\n",
        "    outputCols=[\"{}_imputed\".format(c) for c in ['age', 'Experience', 'Salary']]\n",
        "    ).setStrategy(\"median\")"
      ],
      "metadata": {
        "id": "W4kqhTzyb0Wv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add imputation cols to df\n",
        "imputer.fit(df_pyspark).transform(df_pyspark).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8Cz0r92wrWj",
        "outputId": "6e9d2de3-836c-4f9d-ac9a-24359151f6b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----+----------+------+-----------+------------------+--------------+\n",
            "|     Name| age|Experience|Salary|age_imputed|Experience_imputed|Salary_imputed|\n",
            "+---------+----+----------+------+-----------+------------------+--------------+\n",
            "|    Krish|  31|        10| 30000|         31|                10|         30000|\n",
            "|Sudhanshu|  30|         8| 25000|         30|                 8|         25000|\n",
            "|    Sunny|  29|         4| 20000|         29|                 4|         20000|\n",
            "|     Paul|  24|         3| 20000|         24|                 3|         20000|\n",
            "|   Harsha|  21|         1| 15000|         21|                 1|         15000|\n",
            "|  Shubham|  23|         2| 18000|         23|                 2|         18000|\n",
            "|   Mahesh|null|      null| 40000|         29|                 4|         40000|\n",
            "|     null|  34|        10| 38000|         34|                10|         38000|\n",
            "|     null|  36|      null|  null|         36|                 4|         20000|\n",
            "+---------+----+----------+------+-----------+------------------+--------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}